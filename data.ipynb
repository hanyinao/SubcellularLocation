{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除无法提取pseaac特征的序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "folder_path = r\"D:\\Han\\software\\Math\\CSUpan\\ShareCache\\尹涵(数学与统计学院)\\赛\\一流专业人才计划\\Codes\\data\"\n",
    "file_name_fas = \"uniprotkb_proteome_UP000005640.fasta\"\n",
    "file_name_tsv = \"uniprotkb_proteome_UP000005640.tsv\"\n",
    "\n",
    "file_path_fas = os.path.join(folder_path, file_name_fas)\n",
    "file_path_tsv = os.path.join(folder_path, file_name_tsv)\n",
    "\n",
    "# feature\n",
    "sequences = [str(record.seq) for record in SeqIO.parse(file_path_fas, \"fasta\")]\n",
    "unique_sequences = list(set(sequences))  # 简单去重（完全相同的序列）\n",
    "\n",
    "valid_seqs = []\n",
    "for seq in unique_sequences:\n",
    "    if \"X\" not in seq and \"U\" not in seq:  # 剔除含未知氨基酸（X）或硒代半胱氨酸（U）的序列\n",
    "        valid_seqs.append(seq)\n",
    "\n",
    "# 将字符串序列转换为 SeqRecord 对象列表\n",
    "seq_records = []\n",
    "for i, seq in enumerate(valid_seqs):\n",
    "    record = SeqRecord(Seq(seq), id=f\"seq_{i}\", description=\"\")\n",
    "    seq_records.append(record)\n",
    "\n",
    "file_name_fas_processed = \"cleaned.fasta\"\n",
    "file_path_fas_processed = os.path.join(folder_path, file_name_fas_processed)\n",
    "SeqIO.write(seq_records, file_path_fas_processed, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "df = pd.read_csv(file_path_tsv, sep=\"\\t\", encoding='utf-8')\n",
    "\n",
    "# 1. 过滤实验验证数据\n",
    "df = df[df[\"Protein existence\"] == \"Evidence at protein level\"]\n",
    "df = df[df[\"Subcellular location [CC]\"].str.contains(\"ECO:0000269\", na=False)]\n",
    "\n",
    "# 2. 提取亚细胞定位标签\n",
    "def extract_location(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    locations = text.split(\"SUBCELLULAR LOCATION: \")[-1].split(\";\")[0]\n",
    "    return locations.split(\"{\")[0].strip()\n",
    "\n",
    "df[\"subcellular_location\"] = df[\"Subcellular location [CC]\"].apply(extract_location)\n",
    "\n",
    "# 3.处理多标签分类\n",
    "df[\"subcellular_location\"] = df[\"Subcellular location [CC]\"].apply(\n",
    "    lambda x: [loc.split(\"{\")[0].strip() for loc in x.split(\"SUBCELLULAR LOCATION: \")[-1].split(\";\")]\n",
    ")\n",
    "\n",
    "# 4.删除缺失值\n",
    "df = df.dropna(subset=[\"subcellular_location\"])\n",
    "\n",
    "# 5.删除reviewed列和Protein existence列，重复值\n",
    "df = df.drop(['Reviewed', 'Protein existence', 'Organism'], axis=1)\n",
    "\n",
    "file_name_tsv_to_csv = \"labels.csv\"\n",
    "file_path_tsv_to_csv = os.path.join(folder_path, file_name_tsv_to_csv)\n",
    "df[[\"Entry\",\"Entry Name\" ,\"Sequence\", \"subcellular_location\"]].to_csv(file_path_tsv_to_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subcellular_location\n",
       "[Nucleus]                                                                                                                             1572\n",
       "[Cytoplasm]                                                                                                                           1309\n",
       "[Secreted]                                                                                                                             328\n",
       "[Cell membrane, Multi-pass membrane protein]                                                                                           316\n",
       "[Mitochondrion]                                                                                                                        240\n",
       "                                                                                                                                      ... \n",
       "[Nucleus matrix, Peripheral membrane protein]                                                                                            1\n",
       "[Apical cell membrane, Single-pass type II membrane protein, Single-pass type II membrane protein]                                       1\n",
       "[Cell membrane, Single-pass membrane protein, Cytoplasmic side]                                                                          1\n",
       "[Zymogen granule membrane, Lipid-anchor, GPI-anchor, Lipid-anchor, GPI-anchor, Lipid-anchor, GPI-anchor, Lipid-anchor, GPI-anchor]       1\n",
       "[Nucleus membrane, Single-pass type I membrane protein, Single-pass type I membrane protein]                                             1\n",
       "Name: count, Length: 1434, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计类别分布\n",
    "df_check = pd.read_csv(file_path_tsv_to_csv)\n",
    "df[\"subcellular_location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for record in SeqIO.parse(file_path_fas_processed, \"fasta\"):\n",
    "    data.append({\n",
    "        \"protein_id\": record.id,\n",
    "        \"sequence\": str(record.seq),\n",
    "        \"length\": len(record.seq)\n",
    "    })\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这段代码是实际运用到的初步数据处理代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_path = r\"D:\\Han\\software\\Math\\CSUpan\\ShareCache\\尹涵(数学与统计学院)\\赛\\一流专业人才计划\\Codes\\data\"\n",
    "file_name_tsv = \"uniprotkb_reviewed_true_AND_proteome_up.tsv\"\n",
    "\n",
    "file_path_tsv = os.path.join(folder_path, file_name_tsv)\n",
    "df = pd.read_csv(file_path_tsv, sep=\"\\t\", encoding='utf-8')\n",
    "\n",
    "# 过滤实验验证数据\n",
    "df = df[df[\"Subcellular location [CC]\"].str.contains(\"ECO:0000269\", na=False)]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 2. 提取亚细胞定位标签\n",
    "def extract_location(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    # 提取所有定位并去除证据代码\n",
    "    locations = re.findall(r\"SUBCELLULAR LOCATION: (.*?)\\{\", text)\n",
    "    if locations:\n",
    "        primary_locations = locations[0].split(\". \")\n",
    "        return [loc.strip() for loc in primary_locations if loc.strip()]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df[\"subcellular_location\"] = df[\"Subcellular location [CC]\"].apply(extract_location)\n",
    "\n",
    "# 3.处理多标签分类()\n",
    "\n",
    "\n",
    "# 4.删除缺失值\n",
    "df = df.dropna(subset=[\"subcellular_location\"])\n",
    "df = df.drop(['Subcellular location [CC]'], axis=1)\n",
    "\n",
    "# 数据类型转换\n",
    "df['Length'] = df['Length'].astype(int)\n",
    "df['Mass'] = df['Mass'].astype(float)\n",
    "\n",
    "\n",
    "# 处理结合位点列\n",
    "def extract_binding_features(text):\n",
    "    features = {}\n",
    "    if pd.isna(text):\n",
    "        return features\n",
    "    \n",
    "    # 结合位点数量\n",
    "    binding_sites = re.findall(r\"BINDING (\\d+)\", text)\n",
    "    features[\"num_binding_sites\"] = len(binding_sites)\n",
    "    \n",
    "    # 配体类型统计（例如Fe cation）\n",
    "    ligands = re.findall(r'/ligand=\"([^\"]+)\"', text)\n",
    "    unique_ligands = list(set(ligands))\n",
    "    features[\"num_unique_ligands\"] = len(unique_ligands)\n",
    "    \n",
    "    # 结合位点位置分布\n",
    "    positions = [int(pos) for pos in re.findall(r\"BINDING (\\d+)\", text)]\n",
    "    features[\"binding_pos_mean\"] = np.mean(positions) if positions else 0\n",
    "    features[\"binding_pos_std\"] = np.std(positions) if len(positions) > 1 else 0\n",
    "    \n",
    "    \n",
    "    return features\n",
    "\n",
    "# 应用函数\n",
    "df[\"binding_features\"] = df[\"Binding site\"].apply(extract_binding_features)\n",
    "df_binding = pd.json_normalize(df[\"binding_features\"])\n",
    "df = pd.concat([df, df_binding], axis=1)\n",
    "df.drop('Binding site', axis=1, inplace=True)\n",
    "df.drop('binding_features', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# 2. 处理催化活性列\n",
    "def extract_catalytic_features(text):\n",
    "    features = {}\n",
    "    if pd.isna(text):\n",
    "        return features\n",
    "    \n",
    "    # 提取EC编号（例如EC=1.13.11.18）\n",
    "    ec_match = re.search(r\"EC=(\\d+\\.\\d+\\.\\d+\\.\\d+)\", text)\n",
    "    features[\"ec_number\"] = ec_match.group(1) if ec_match else 0\n",
    "    \n",
    "    # 提取反应底物和产物\n",
    "    substrates = re.findall(r\"Reaction=([^=]+)\\s*=\", text)\n",
    "    products = re.findall(r\"=\\s*([^;]+)\", text.split(\"Reaction=\")[-1]) if \"Reaction=\" in text else []\n",
    "    features[\"num_substrates\"] = len(substrates)\n",
    "    features[\"num_products\"] = len(products)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 应用函数\n",
    "df[\"catalytic_features\"] = df[\"Catalytic activity\"].apply(extract_catalytic_features)\n",
    "df_catalytic = pd.json_normalize(df[\"catalytic_features\"])\n",
    "df = pd.concat([df, df_catalytic], axis=1)\n",
    "df.drop('Catalytic activity', axis=1, inplace=True)\n",
    "df.drop('catalytic_features', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# df.drop('Entry Name', axis=1, inplace=True)\n",
    "# df\n",
    "\n",
    "file_name_tsv_to_csv = \"data.csv\"\n",
    "file_path_tsv_to_csv = os.path.join(folder_path, file_name_tsv_to_csv)\n",
    "df.to_csv(file_path_tsv_to_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "try",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
